{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "reviews = pd.read_csv('home_products_additional_features.csv', header=0, encoding=\"ISO-8859-1\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_nmf(nmf_features, nmf_topics, nmf_top_words, nmf_data_samples, nmf_max_df, nmf_min_df, nmf_alpha, nmf_l1_ratio):\n",
    "    print(\"Extracting tf-idf features for NMF...\")\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=max_df, min_df=min_df,\n",
    "                                       max_features=n_features,\n",
    "                                       stop_words='english')\n",
    "\n",
    "    tfidf = tfidf_vectorizer.fit_transform(nmf_data_samples)\n",
    "\n",
    "    nmf = NMF(n_components=n_topics, random_state=1,\n",
    "              alpha=alpha, l1_ratio=l1_ratio).fit(tfidf)\n",
    "\n",
    "    print(\"\\nTopics in NMF model:\")\n",
    "    tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "    print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_lda(lda_features, lda_topics, lda_top_words, lda_data_samples, lda_max_df, lda_min_df, lda_max_iter, lda_learning_offset):\n",
    "    tf_vectorizer = CountVectorizer(max_df=lda_max_df, min_df=lda_min_df,\n",
    "                                    max_features=lda_features,\n",
    "                                    stop_words='english')\n",
    "    \n",
    "    tf = tf_vectorizer.fit_transform(lda_data_samples)\n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_topics=lda_topics, max_iter=lda_max_iter,\n",
    "                                    learning_method='online',\n",
    "                                    learning_offset=lda_learning_offset,\n",
    "                                    random_state=0)\n",
    "    \n",
    "    lda.fit(tf)\n",
    "    \n",
    "    print(\"\\nTopics in LDA model:\")\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    print_top_words(lda, tf_feature_names, lda_top_words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "clorox wipes convenient products use disinfect using house disinfects home like family cleaning germs trust especially know messes kids bleach\n",
      "Topic #1:\n",
      "stars price works work wipes glasses fast excellent job described great expected deal perfect time exactly worked shipping thank service\n",
      "Topic #2:\n",
      "great product works price work use cleaning excellent wipes recommend value cleans products job buy smells smell home deal house\n",
      "Topic #3:\n",
      "love wipes smell use using house absolutely convenience home products room smells kids scent em especially cleans product kitchen day\n",
      "Topic #4:\n",
      "good product price value smell really wipes job like buy works cleaning smells cleans stuff quality pretty screen deal work\n",
      "Topic #5:\n",
      "easy use convenient quick wipes kids cleanup fast cleaning super disinfect makes effective grab time clean make wipe mess messes\n",
      "Topic #6:\n",
      "disinfecting wipes lysol lemon cleaning scent pack great value convenient germs lime time surfaces job fresh home favorite especially power\n",
      "Topic #7:\n",
      "best wipes cleaning used stainless use product market tried thing cleaner steel products glasses lens brand disinfectant brands wipe far\n",
      "Topic #8:\n",
      "awesome product wipes house stuff cleaning convenience work recommend really use smell bathroom super amazing family make counters mess products\n",
      "Topic #9:\n",
      "clean wipes title bathroom kitchen cleaning wipe use like quick house smell work really fresh handy time nice home germs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#////////////////////////SET NMF PARAMETERS AND RUN MODEL/////////////////////////////\n",
    "\n",
    "# Uncomment one of the lines (and only one line) that begins with nmf_data_samples to change the data set the model runs on\n",
    "\n",
    "#nmf_data_samples = list(reviews['Text'])\n",
    "#nmf_data_samples = list(reviews['Title'])\n",
    "#nmf_data_samples = list(reviews['text_and_title'])\n",
    "#nmf_data_samples = list(reviews['double_title'])\n",
    "#nmf_data_samples = list(reviews['text_and_title_no_stops'])\n",
    "nmf_data_samples = list(reviews['double_title_no_stops'])\n",
    "#nmf_data_samples = list(reviews['text_and_title_negation'])\n",
    "#nmf_data_samples = list(reviews['double_title_negation'])\n",
    "#nmf_data_samples = list(reviews['text_and_title_negation_no_stops'])\n",
    "#nmf_data_samples = list(reviews['double_title_negation_no_stops'])\n",
    "#nmf_data_samples = list(reviews['lemma_text_title_no_stops'])\n",
    "#nmf_data_samples = list(reviews['lemma_double_title_no_stops'])\n",
    "\n",
    "nmf_features = 10000         # Size of the vocabulary\n",
    "nmf_topics = 10              # Number of topics\n",
    "nmf_top_words = 20           # Words to include in the topic\n",
    "nmf_max_df=0.95              # Ignore terms that have a doc frequency (percent or int) strictly higher than the given threshold\n",
    "nmf_min_df=2                 # Ignore terms that have a doc frequency (percent or int) strictly lower than the given threshold\n",
    "nmf_alpha=.1                 # Constant that multiplies the regularization terms. Set to zero for no regularization.\n",
    "nmf_l1_ratio=.5              # Regularization mixing parameter.  0 <= l1_ratio <= 1\n",
    "\n",
    "run_nmf(nmf_features, nmf_topics, nmf_top_words, nmf_data_samples, nmf_max_df, nmf_min_df, nmf_alpha, nmf_l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "travel cover icloth equipment portable pinch ocd 24 pas kit\n",
      "Topic #1:\n",
      "great product good work value cleaning steel use stainless job\n",
      "Topic #2:\n",
      "star grease work cut good wipe love oil clean tool\n",
      "Topic #3:\n",
      "nice super baby puppy money waste softy generation seventh sturdy\n",
      "Topic #4:\n",
      "floor clean water ok hard scrub use dirt dirty tile\n",
      "Topic #5:\n",
      "excellent save quality silver product clear high subscribe expect regular\n",
      "Topic #6:\n",
      "wipe clorox clean love use easy disinfect bathroom kitchen house\n",
      "Topic #7:\n",
      "glass lens use clean effective live time day wipe year\n",
      "Topic #8:\n",
      "wipe clean work use screen good leave dust best job\n",
      "Topic #9:\n",
      "fast chemical smell review buy natural durable powerful skin green\n",
      "Topic #10:\n",
      "touchscreen im awsome received station hesitant luv thankful spic span\n",
      "Topic #11:\n",
      "lysol smell scent wipe lemon price fresh strong disinfect great\n",
      "Topic #12:\n",
      "flu office season cold especially shoe bug lifesaver bay pen\n",
      "Topic #13:\n",
      "spray towel surface paper bottle expensive mirror stick prefer kind\n",
      "Topic #14:\n",
      "appliance stainless bad school wish hold teacher look terrible read\n",
      "Topic #15:\n",
      "wipe like dry use good cloth wet container box package\n",
      "Topic #16:\n",
      "perfect pack fantastic fine husband store dispenser bath amazon come\n",
      "Topic #17:\n",
      "handy come dog useful pet color stock em potty paw\n",
      "Topic #18:\n",
      "clorax meh convient sad semi desinfecting convinient photographer gem wasteful\n",
      "Topic #19:\n",
      "brand car wipe use disinfectant new trust amaze clean try\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#////////////////////////SET LDA PARAMETERS AND RUN MODEL/////////////////////////////\n",
    "\n",
    "# Uncomment one of the lines (and only one line) that begins with lda_data_samples to change the data set the model runs on\n",
    "\n",
    "#lda_data_samples = list(reviews['Text'])\n",
    "#lda_data_samples = list(reviews['Title'])\n",
    "#lda_data_samples = list(reviews['text_and_title'])\n",
    "#lda_data_samples = list(reviews['double_title'])\n",
    "#lda_data_samples = list(reviews['text_and_title_no_stops'])\n",
    "#lda_data_samples = list(reviews['double_title_no_stops'])\n",
    "#lda_data_samples = list(reviews['text_and_title_negation'])\n",
    "#lda_data_samples = list(reviews['double_title_negation'])\n",
    "#lda_data_samples = list(reviews['text_and_title_negation_no_stops'])\n",
    "#lda_data_samples = list(reviews['double_title_negation_no_stops'])\n",
    "#lda_data_samples = list(reviews['lemma_text_title_no_stops'])\n",
    "lda_data_samples = list(reviews['lemma_double_title_no_stops'])\n",
    "\n",
    "lda_features = 12000         # Size of the vocabulary \n",
    "lda_topics = 20              # Number of topics\n",
    "lda_top_words = 10           # Words to include in the topic\n",
    "lda_max_df= 0.95             # Ignore terms that have a doc frequency (percent or int) strictly higher than the given threshold\n",
    "lda_min_df= 5                # Ignore terms that have a doc frequency (percent or int) strictly lower than the given threshold\n",
    "lda_max_iter=5               # Number of iterations to compute\n",
    "lda_learning_offset=50.      # A parameter that downweights early iterations in online learning. Should be > 1\n",
    "\n",
    "run_lda(lda_features, lda_topics, lda_top_words, lda_data_samples, lda_max_df, lda_min_df, lda_max_iter, lda_learning_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
